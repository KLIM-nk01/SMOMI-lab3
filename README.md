# Лабораторная работа 3.

**Цель лабораторной работы:**  Исследовать влияние параметра “темп обучения” на
процесс обучения нейронной сети на примере решения задачи классификации Food-101 с
использованием техники обучения Transfer Learning

**Задачи:**

1. С использованием [1] и техники обучения Transfer Learning обучить нейронную сеть
EfficientNet-B0 (предварительно обученную на базе изображений imagenet) для
решения задачи классификации изображений Food-101 с использованием
фиксированных темпов обучения 0.01, 0.001, 0.0001
2. Реализовать и применить в обучении следующие политики изменения темпа
обучения, а также определить оптимальные параметры для каждой политики:
a. Косинусное затухание (Cosine Decay) [2,4]
b. Косинусное затухание с перезапусками (Cosine Decay with Restarts) [3,4]

<hr/>

##Графики обучения нейронной сети EfficientNet-B0(предварительно обученную на базе изображений imagenet), фиксированный темп обучения 0.01, 0.001, 0.0001##


***График метрики точности (валидационные данные):***
![image](https://user-images.githubusercontent.com/56519328/116857070-dba80380-ac04-11eb-8f6f-6d2324459e95.png)

***График функции потерь (валидационные данные):***
![image](https://user-images.githubusercontent.com/56519328/116857707-ec0cae00-ac05-11eb-84eb-de0f31d7e606.png)

***График метрики точности (тренировочные данные):***
![image](https://user-images.githubusercontent.com/56519328/116857553-abad3000-ac05-11eb-94f2-d10d81e55ca4.png)

***График функции потерь (тренировочные данные):***
![image](https://user-images.githubusercontent.com/56519328/116857680-e1521900-ac05-11eb-8185-f91f032691fd.png)


***Анализ полученных результатов***
Анализируя полученные графики для первой задачи, можно утверждать, что оптимальным параметром фиксированного темпа обучения для нейронной сети EfficientNet-B0 (предварительно обученную на базе изображений imagenet) для решения задачи классификации изображений Food-101, является параментр равный 0.0001, так как наибольшая точность на графике точности для валидационных данных - 67%, достигнута именно с этим параметром, а так же наименшее значение на графике функции  потерь - 1.209.

<hr/>

##Реализовать и применить в обучении следующие политики изменения темпа
обучения, а также определить оптимальные параметры для каждой политики:
a. Косинусное затухание (Cosine Decay)##

```python
tf.keras.experimental.CosineDecay(initial_learning_rate, decay_steps)
```

***График метрики точности:***
![image](https://user-images.githubusercontent.com/56519328/116806456-ca43f600-ab35-11eb-85d8-dfe48f2b8490.png)
![image](https://user-images.githubusercontent.com/56519328/116806459-d16b0400-ab35-11eb-90f5-6e8513cc6f9b.png)


***График функции потерь:***
![image](https://user-images.githubusercontent.com/56519328/116806472-e34ca700-ab35-11eb-93c5-339967b5cb71.png)
![image](https://user-images.githubusercontent.com/56519328/116806476-e9db1e80-ab35-11eb-985b-a2e131ee2fc3.png)


 **Графики темпов обучения**
 
![image](https://user-images.githubusercontent.com/56519328/116860249-f3ce5180-ac09-11eb-885d-8c1a3578b52d.png)
 
![image](https://user-images.githubusercontent.com/56519328/116860640-8e2e9500-ac0a-11eb-88d5-25902b056c9d.png)

![image](https://user-images.githubusercontent.com/56519328/116860992-12811800-ac0b-11eb-8728-1f7c60fb02e6.png)

***Анализ полученных результатов***
В ходе выполнения 3а задачи для политики Cosine Decay, я изменял параметры initial_learning_rate и decay_steps, получились следующие наборы параметров: 
![image](https://user-images.githubusercontent.com/56519328/116862273-2f1e4f80-ac0d-11eb-8c31-60649e886a98.png)
где первый параметр initial_learning_rate а второй соответсвенно decay_steps. Анализируя полученные графики, могу утверждать, что оптимальными параметрами для политики Cosine Decay из приведенных выше параметров, являются параметры initial_learning_rate = 0.001 и decay_steps = 30000, так как на графике точности для валидационных данных была достигнута наибольшая точность равная 67% и наименьшее значение функции потерь 1.214

<hr/>
 
##Реализовать и применить в обучении следующие политики изменения темпа
обучения, а также определить оптимальные параметры для каждой политики:
b. Косинусное затухание с перезапусками (Cosine Decay with Restarts)##

 ```python
tf.keras.experimental.CosineDecayRestarts(initial_learning_rate, first_decay_steps, t_mul=2.0, m_mul=1.0)
```
 

***Анализ полученных результатов***

